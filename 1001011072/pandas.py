# -*- coding: utf-8 -*-
"""Pandas.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OY8Oy6rT_FyNwDMp07Td_08EB7UHncoa
"""

#recomendacion aprender bash

"""[tips de python](https://github.com/restrepo/PythonTipsAndTricks)

>[Pandas](#scrollTo=d8BGX58hxE06)

>>[Standard way to load the module](#scrollTo=zd4jo7KLxE1C)

>>[Introduction](#scrollTo=Ir8urIlIKJ71)

>>[Basic structure: DataFrame](#scrollTo=I7Hbe9JEadOC)

>>[Data structures](#scrollTo=HeN8rw1JxE1N)

>>>[DataFrame](#scrollTo=uRdBR4BXc8WY)

>>>>[Export DataFrame to other formats](#scrollTo=ZMc0puXbe3nD)

>>>[Series](#scrollTo=c_bj3IfLxE1Q)

>>[DataFrame initialization](#scrollTo=Kab6pfyMxE1k)

>>>[Initialization from an existing spreadsheet.](#scrollTo=4zhJVNq1pTTe)

>>>[Initialization from lists and dictionaries](#scrollTo=QZUHeScjp6cC)

>>>>[Inizialization from Series](#scrollTo=5ulKgKBRxE1m)

>>>>[Column oriented way](#scrollTo=J-F92xHmp8v7)

>[Special dataframes](#scrollTo=ZbslNGIm5YbY)

>>>>[Single row DataFrame from dictionary](#scrollTo=ttkPJIMP57n2)

>>>[Initialization from sequential rows as  Series](#scrollTo=jh67bj_B6Zyb)

>>>>[Exercises](#scrollTo=OMekcD9q6Zyd)

>>[Other formats to saving and read files](#scrollTo=rzAKwxQhxE2a)

>>>[CSV](#scrollTo=w8hdIGOvu3Ee)

>>>[JSON](#scrollTo=s1rbHbLmuv2g)

>>[Common operations upon DataFrames](#scrollTo=pAZISlqKxE2T)

>>[Filters (masking)](#scrollTo=s2uApSIi8PjI)

>>[The apply method](#scrollTo=xHsCPml65i54)

>>>[Column-level apply](#scrollTo=378RNNb97OQs)

>>>[Row-level apply](#scrollTo=8wFVd7Sk7irH)

>>[Chain tools for data analysis](#scrollTo=glxOt9V7KJ8O)

>>[Relational databases](#scrollTo=n2pBbtfwKJ8P)

>>>[Activity](#scrollTo=pZVl8EzRKJ8P)

>>[Non-relational databases](#scrollTo=z2NsLagWs-Jg)

>>>[Actividad](#scrollTo=mWFzC6W4KJ8R)

>>[World wide web](#scrollTo=wB4hBVkhoPwR)

>>>[Normal web](#scrollTo=wMgIx5LJKJ8R)

>>>[Machine web](#scrollTo=690YFkeIKJ8R)

>>[Summary](#scrollTo=UrrgwzFtKJ8S)

>>[ACTIVITIES](#scrollTo=D7SNm2ABxE22)

>>[Final remarks](#scrollTo=fWjYdB7LxE23)

# Pandas

From http://pandas.pydata.org/pandas-docs/stable/

pandas is a Python package providing fast, flexible, and expressive data structures designed to make working with “relational” or “labeled” data both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, real world data analysis in Python. Additionally, it has the broader goal of becoming the most powerful and flexible open source data analysis / manipulation tool available in any language. It is already well on its way toward this goal.

See also:

* https://github.com/restrepo/data-analysis
  * https://classroom.github.com/g/sSMBdBqN
  * https://classroom.github.com/a/PcbQBE7F
* https://github.com/restrepo/PythonTipsAndTricks
* https://pbpython.com/excel-pandas-comp.html [[archive.org](https://web.archive.org/web/20201126143453/https://pbpython.com/excel-pandas-comp.html)]

Good and practice books about `Pandas` possibilities are:


[__Python for Data Analysis__](https://drive.google.com/open?id=0BxoOXsn2EUNIWExXbVc4SDN0YTQ)<br/>
Data Wrangling with Pandas, NumPy, and IPython<br/>
_By William McKinney_


This other is about aplications based on `Pandas`:
![image.png](https://covers.oreillystatic.com/images/0636920030515/cat.gif) [Introduction to Machine Learning with Python](https://drive.google.com/open?id=0BxoOXsn2EUNISGhrdEZ3S29fS3M)<br/>
A Guide for Data Scientists
By Sarah Guido, Andreas Müller

[Python Books](https://drive.google.com/drive/u/0/folders/0BxoOXsn2EUNIUFFUWUkxd0JSVFk?resourcekey=0-Eo6AxHgut_mZ1-M3vD10oQ)

`Pandas` can be used in a similar way to `R`, which is based on similar data structures. `Pandas` also can replace the use of graphical interfaces to access spreadsheets like Excel. In particular, can be used in joint with the module [`xlsxwriter`](https://xlsxwriter.readthedocs.io/tutorial02.html) to produce professional Excel spreadsheets at the programatical level.

The similar data structure in Wolfram Alpha and Mathematica is  the `Dataset`, in C++ is the ROOT framework, and in the old Fortran 77 was `paw`. In this way, a dictionary of equivalent commands can be stablished between the several frameworks

```{contents}
:depth: 2
```

## Standard way to load the module
"""

import pandas as pd         #forma de importar un pandas

"""## Introduction

We already saw how NumPy arrays can improve the analysis of numerical data. For heterogeneous data the recommended tool are Pandas dataframes.

Heterogeneous and nested data can be stored as list of dictionaries. For example, for people with names, birth date, sex, and a job list with start and end date, we can jave
"""

# Create a dictionary for each person's data
person1 = {"Name": "John Doe", "Birth Date": "01-01-1980", "Sex": "Male", 
           "Job": [{"Job Title": "Software Engineer", "Start Date": "01-01-2000", "End Date": "01-01-2005"}, 
                   {"Job Title": "Data Scientist", "Start Date": "01-01-2005", "End Date": None}]}
person2 = {"Name": "Jane Doe", "Birth Date": "01-01-1985", "Sex": "Female", 
           "Job": [{"Job Title": "Product Manager", "Start Date": "01-01-2010", "End Date": "01-01-2015"}, 
                   {"Job Title": "Project Manager", "Start Date": "01-01-2015", "End Date": "01-01-2020"}]}
person3 = {"Name": "Jim Smith", "Birth Date": "01-01-1990", "Sex": "Male", 
           "Job": [{"Job Title": "Data Analyst", "Start Date": "01-01-2010", "End Date": "01-01-2015"}, 
                   {"Job Title": "Business Analyst", "Start Date": "01-01-2015", "End Date": "01-01-2020"}]}
person4 = {"Name": "Sara Johnson", "Birth Date": "01-01-1995", "Sex": "Female", 
           "Job": [{"Job Title": "Product Designer", "Start Date": "01-01-2015", "End Date": "01-01-2020"}, 
                   {"Job Title": "UX Designer", "Start Date": "01-01-2020", "End Date": None}]}

# Create a list of dictionaries
people = [person1, person2, person3, person4]

person1.get('Job')[0].get('Job Title')    #forma de acceder a uno de los elementos cuando tengo un diccionario con listas de diccionarios adentro

"""We can create a DataFrame from the list of dictionaries"""

df = pd.DataFrame(people)             #defino un dataframe a partir de el previo diccionario
df

#con pandas puedo convertir una lista de diccionarios en un dataframe
#las columnas corresponden a las claves del diccionario

"""As with NumPy, we can create masks in ordert to filter out specific rows of the dataframe. For example, to filter out the female persons by using the syntax:"""

df[df["Sex"] == "Female"]               #como en las mascaras de numpy, podemos realizar máscaras para filtrar la informacion (FILTRACION DE LA IFORMACIÓN)


#EL RESULTADO ES UN NUEVO DATAFRAME CON LA INFORMACIÓN FILTRADA

"""To filter out the last job of each person by using the following code (`.get` is a safer way to obtain the value of the key of a dictionary)"""

#SOBRE EL DATAFRAME ORIGINAL VAMOS A FILTRAR EL ULTIMO TRABAJO QUE HAYAN TENIDO

df['Last job']=df["Job"].apply(lambda L: L[-1].get('Job Title'))   #DEFINO LA FUNCIÓN DE FORMA IMPLÍCITA, Y SE EXTRAE EL ULTIMO ELEMENTO DEL DICCIONARIO JOB TITLE
                                                                   #EL LAMBDA LO QUE HACE ES RECURSIVAMENTE TOMAR Y APLICAR A CADA UNO DE LOS ELEMENTOS DEL DATAFRAME
                                                                   #ESTE POR EJEMPLO ES UN TIPO DE DATOS HETEROGENEOS, DONDE UNA DE LAS COLUMNAS ES UNA LISTA
                                                                   #L SERÍA CADA UNO DE LOS ELEMENTOS EN LA COLUMNA DEL DATAFRAME
                                                                   #recordamos que en las funciones lambda lo que aparece despues del lambda es el argumento que toma la función
                                                              

df[['Name','Birth Date','Sex','Last job']]

#VAMOS A HACER LO MISMO ANTERIOR, PERO DEFINIENDO LA LISTA POR APARTE

def get_value(L, k='Job Title'):      #debe ingresar una lista y una clave por defecto
  return L[-1].get(k)


df['Last job']=df["Job"].apply(get_value)     #como si la funcion tuviera un solo argumento
df[['Name','Birth Date','Sex','Last job']]

#la función lamba se usa cuando se usan funciones de mas de un argumento

df['Last job']=df["Job"].apply(lambda L: get_value(L, 'Job Title'))                   #en caso de que quiera definir la segunda variable de la funcion
df[['Name','Birth Date','Sex','Last job']]

"""## Basic structure: DataFrame

An flat _spreadsheet_ can be seen in terms of the types of variables of `Python` just as dictionary of lists, where each column of the spreadsheet is a pair key-list of the dictionary 

|   |  A   |  B   |
|---|:----:|:----:|
| 1 | even | odd  |
| 2 |   0  | 1    |
| 3 |   2  | 3    |
| 4 |   4  | 5    |
| 5 |   6  | 7    |
| 6 |   8  | 9    |
"""

numbers={"even": [0,2,4,6,8],   #  First  key-list                                 #AQUÍ TENEMOS UN DICCIONARIO DE LISTAS
         "odd" : [1,3,5,7,9] }  #  Second key-list

pd.DataFrame(numbers)                #tener un diccionario de listas es lo mismo que tener una lista de diccionario --> funciona igual para pandas

"""## Data structures

`Pandas` has two new data structures:
1. `DataFrame` which are similar to numpy arrays but with some assigned key. For example, for the previous case
```python
import numpy as np
np.array([[0,1],
          [2,3],
          [4,5],
          [6,7],
          [8,9] 
         ])
```
1. `Series` which are enriched  to dictionaries, as the ones defined for the rows of the previous example: `{'even':0,'odd':1}`.
"""

#las series son diciconarios enriquecidos         --> forma enriquecida de un diccionario
#la forma enriquecida de una lista es un arreglo  --> forma enriquecida de una lista

"""The rows in a two-dimensional `DataFrame` corresponds to `Series` with similar keys, while the columns are also Series with the indices as keys. 

An example of a  `DataFrame` is a spreadsheet, as the one before.

### `DataFrame`

`Pandas` can convert a dictionary of lists, like the `numbers` dictionary before, into a `DataFrame`, which is just an spreadsheet but interpreted at the programming level:
"""

numbers

import pandas as pd
df=pd.DataFrame(numbers)
df

import matplotlib.pyplot as plt

plt.plot(df['even'],df['odd'])

"""See below for other possibilities of [creating Pandas DataFrames from lists and dictionaries](https://fisica.udea.edu.co:4443/user/restrepo/notebooks/prog/cursos/data-analysis/Pandas.ipynb#Intialization-from-lists-and-dictionaries)

The main advantage of the `DataFrame`,`df`, upon a spreadsheet, is that it can be managed just at the programming level without any graphical interface.

We can check the shape of the `DataFrame`
"""

df.shape   #se usa --.shape cuando quiero saber el tamaño de un dataframe       #ES UNO DE LOS ATRIBUTOS DE PANDAS

#LOS DATAFRAME CONSERVAN ATRIBUTOS DE LOS DICCIONARIOS

"""####  Export DataFrame to other formats

* To export to excel:
"""

df.to_excel('example.xlsx',index=False)        #FORMA DE EXPORTAR A UN EXCEL, SE PONE FALSE PARA QUE NO PONGA LA COLUMNA CON LOS INDICES

newdf=pd.read_excel('example.xlsx')
newdf                                          #UN DATAFRAME PUEDE LEER ARCHIVOS DE EXCEL

newdf['fractions']=[0.5,2.5,4.5,6.5,8]                   #ASI TENGA UNA LISTA CON PURO FLOAT Y UN INT, EL DATAFRAME INTENTA PONER TODOS LOS DATOS DE FORMA HOMOGENEA
newdf

newdf['next fractions']=1.5
newdf

newdf.loc[3,'next to next fractions']=1.7                  #.loc ES PARA ACCEDER A UNA CELDA
                                                           #SE PONE PRIMERO EL VALOR DE LA FILA QUE SE QUIERE CAPTURAR, Y LUEGO LA COLUMNA QUE QUIERO
newdf


#EN ESTE CASO LA COLUMNA NO EXISTÍA, PERO CREA UNA NUEVA; y en este caso el valor que se ha asignado es determinado para que aparezca solamente en la fila numero 3

"""__Activity__: Open the resulting spreadsheet in Google Drive, publish it and open from the resulting link with Pandas in the next cell"""

#notamos que con lo anterior y lo contenido en las dos siguientes celdas

newdf.to_excel('archivo de ejemplo.xlsx', index=False)

importado = pd.read_excel('https://docs.google.com/spreadsheets/d/e/2PACX-1vTe60EuttXFdKe5VIPpGsqWPU-tUKkDsN-1lEfk1hlaYkPP97sslfBFnm_6lMtqXg/pub?output=xlsx')
importado

df=pd.read_excel('https://docs.google.com/spreadsheets/d/e/2PACX-1vTjBBepYSJSICQtxXRdMrJk3fN-SSAE3uu5-54A-zOknX8mnWf01u2WszaXCtcagkhQVcQvK9-LVpu3/pub?output=xlsx')             #SE PONE EL ENLACE DE UN DOCUMETNO QUE ESTÉ EN LA WEB, LO MONTO PONIENDO EN SHEETS DE GOOGLE Y SE LO DA A PUBLICAR
df

#ESTO SIGNIFICA QUE SE PUEDEN CARGAR DOCUMENTOS DIRECTAMENTE DESDE LA NUBE, O BIEN, SI ESTÁ EN EL DISCO DURO SE PUEDE CARGAR NORMALITO

df=pd.read_excel('https://docs.google.com/spreadsheets/d/e/2PACX-1vQ1HFwErJcHkkOCT4Je-yuLSRe2L_GKWcCGVooc6rbOvTLxJhqglTZh31I_eB_dcw/pub?output=xlsx')
df

"""### `Series`

Each column of the DataFrame is now an augmented dictionary called `Series`, with the indices as the keys of the `Series`

A `Pandas` `Series` object can be just initialized from a `Python` dictionary:
"""

df['even']    #ACCEDO A LA CLAVE DE UN DICCIONARIO

type( df['even'] )

df.even   #ACCEDO A LA CLAVE PERO EN FORMA DE UN ATRIBUTO

"""The keys are the index of the `DataFrame`"""

#df['even']
df.even[4]

"""Each row is also a series"""

df.loc[0]          #CADA FILA TAMBIÉN REPRESENTA UNA SERIE

"""with keys: `'even'` and `'odd'`

or as a filter
"""

df.loc[[4]]  #FILA EN DOBLE COCHETE, PERO MANTENIENDO LA FORMA DE UN DATAFRAME

df.loc[0]['even']   #COMO ELEMENTOS DEL DATAFRAME

"""or attributes `even` and `odd`"""

df.loc[0].odd        #COMO ATRIBUTOS DE UN DATAFRAME

"""One specific cell value can be reached with the index and the key:"""

df.loc[2,'odd']

df.at[2,'even']             #AT ES COMO UN SINÓNIMO DE LOC, PERO ES MAS PODEROSO EN TERMINOS DE QUE SE PUEDE AÑADIR COLUMNAS CON ELEMENTOS MAS COMPLEJOS QUE SOLAMENTE STRINGS O NUMEROS
                            #A DIFERENCIA DE LO QUE SE PUEDE HACER CON LOC

"""A `Pandas` `Series` object can be just initialized from a `Python` dictionary:"""

s=pd.Series({'Name':'Juan Valdez','Nacionality':'Colombia','Age':23})
s

s['Name']

"""but also as containers of name spaces!"""

s.Name

"""> The __power__ of Pandas rely in that their main data structures: `DataFrames` and `Series`, are enriched with many useful methods and attributes.

__[Official definition of Pandas](http://pandas.pydata.org/pandas-docs/stable/)__

> Pandas is a Python package providing __fast__, __flexible__, and __expressive__ _data structures_ designed to make working with “relational” or “labeled” data both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, real world data analysis in Python. Additionally, it _has the broader goal of becoming the most powerful and flexible open source data analysis / manipulation tool_ available in any language. It is already well on its way toward this goal.

* "relational": the list of data is identified with some unique index (like a `SQL` table)
* "labeled": the list is identified with a key, like the previous `odd` or `even` keys.

For example. A double bracket `[[...]]`, can be used to filter data.

A row in a two-dimensional `DataFrame` corresponds to `Series` with the same keys of the `DataFrame`, but with single values instead of a list
"""

df.loc[[0]]

"""To filter a column:"""

df[['odd']]

"""## `DataFrame` initialization

### Initialization from an existing spreadsheet.

This can be locally in your computer o from some downloadable  link
"""

#filetype xlsx con cualquier nombre adelante saca archivos de excel

df=pd.read_excel('http://bit.ly/spreadsheet_xlsx')
df

"""To make a downloadable link for any spread sheet in Google Drive, follow the sequence:
```
File → Publish to the web...→ Entire Document → Web page → Microsoft excel (xlsx)
```
as illustrated in the figure:
![GS](https://github.com/restrepo/data-analysis/blob/master/img/img1.png?raw=1)
"""

df.loc[0,'Edad']=32
#df.at[0,'Edad']=32
df

"""*After* some modification

it can be saved again as an `excel file` with the option to not create a column of indices: `index=False`

### Initialization from lists and dictionaries

#### Inizialization from Series
We start with an empty `DataFrame`:

Creating Pandas DataFrame from list and dictionaries [offers many alternatives](http://pbpython.com/pandas-list-dict.html)

![creating dataframes](http://pbpython.com/images/pandas-dataframe-shadow.png)

#### Column oriented way
* In addition to the dictionary of lists [already illustrated at the beginning]() that in this case corresponds to:
"""

pd.DataFrame({'Nombre'   : ['Juan Valdez','Álvaro Uribe Vélez'],
              'Edad'     : [32,            69                 ],
              'Compañia' : ['Café de Colombia','Senado de la República']})

"""* We can obtain the DataFrame from list of items"""

pd.DataFrame([ [ 'Nombre'  , ['Juan Valdez','Álvaro Uribe Vélez']],
                          [ 'Edad'    , [  32,            65               ]],
                          [ 'Compañia', ['Café de Colombia','Senado de la República']] ])

"""* We can obtain the `DataFrame` from dictionary"""

pd.DataFrame( [{'Nombre':'Juan Valdez',        'Edad': 32   ,'Compañia':'Café de Colombia'      },
              {'Nombre':'Álvaro Uribe Vélez', 'Edad': 65   ,'Compañia':'Senado de la República'}]
            )

"""#Special dataframes"""

df=pd.DataFrame()
df

df.empty   #me habla de que el dataframe no tiene datos

"""un dataframe vacio sirve para meterle datos

#### Single row DataFrame from dictionary
"""

d={
    'first key' :'first value',
    'second key':'second value'

  }
pd.DataFrame([d])

"""### Initialization from sequential rows as  Series

We start with an empty `DataFrame`:
"""

import pandas as pd
df=pd.DataFrame()
df.empty

"""We can append a dictionary (or Series) as a row of the `DataFrame`, provided that we always use the option: `ignore_index=True`"""

d={'Name':'Juan Valdez','Nacionality':'Colombia','Age':23}
df=pd.concat((df,pd.DataFrame([d])))
df

d= {'Job': 'Barrendero', 'Cédula': '555'}
pd.concat((df, pd.DataFrame([d])))

d= {'Job': 'Barrendero', 'Cédula': '555'}
pd.concat((df, pd.DataFrame([d]))).fillna(0)  #lo mismo del anterior, pero donde sale nan lo cambio por un cero

#para agregarlo horizontal:

import pandas as pd
df=pd.DataFrame()
df.empty

d={'Name':'Juan Valdez','Nacionality':'Colombia','Age':23}
df=pd.concat((df,pd.DataFrame([d])), axis=1)                 #asi se agrefan elementos a la misma fila, y tambien se puede ---> axis='columns'
df

d= {'Job': 'Barrendero', 'Cédula': '555'}
pd.concat((df, pd.DataFrame([d])))

"""To add a second file we build another `dict`"""

#vamos a adicionar una segunda fila


import pandas as pd
df=pd.DataFrame()
df.empty


d={'Name':'Juan Valdez','Nacionality':'Colombia','Age':23}
df=pd.concat((df,pd.DataFrame([d])), axis=1)                 #asi se agregan elementos a la misma fila, y tambien se puede ---> axis='columns'
df

d={}
for k in ['Name','Nacionality','Age','Company']:
    var=input('{}:\n'.format(k))
    if k== 'Age':
      var = int(var)
    d[k]=var

d

df=pd.concat([df,pd.DataFrame([d])])

df

"""#### Exercises
* Display the resulting `Series` in the screen:
"""

df['Name']

"""__Activity__: Append a new row to the previous `DataFrame` and visualize it:"""



"""* Fill NaN with empty strings"""

df=df.fillna('')

df

"""* Save `Pandas` `DataFrame` as an Excel file"""

df.to_excel('prof.xlsx',index=False)

"""* Load pandas DataFrame from the saved file in Excel"""

pd.read_excel('prof.xlsx')

"""## Other formats to saving and read files

We are interested in format which keeps the tags of the columns, like `'Nombre', 'Edad', 'Compañia'`
"""

import pandas as pd

df=pd.read_excel('http://bit.ly/spreadsheet_xlsx')
df

type(df.loc[0,'Edad'])

"""### CSV

Comma separated values
"""

df.to_csv('hoja.csv',index=False)      #csv is comma separated value --> se crea un archivo de texto

cat hoja.csv  #cat muestra los contenidos de un archivo en el disco duro de la maquina virtual

"""We can check the explicit file format with"""

print(df.to_csv(None,index=False))     #si le pongo none lo escribe solo como una cadena de caracteres

pd.read_csv('hoja.csv')     #como se creó previamente, podemos solo leerlo

"""### JSON

This format keeps the Python lists and dictionaries at the storage level
"""

df=pd.DataFrame([{"Name":"Donald Trump","Age":74},               #la unica diferencia es que las strings siempre están en comillas dobles
                 {"Name":"Barak Obama", "Age":59}])
df

"""This format allow us to keep exactly the very same list of dictionaries structure!"""

print(df.to_json(None,orient='records'))   #el metodo to jason es para guardar cosas al json


#orient records es para que se imponga el estandar correcto al jason   -->SIEMPRE QUE SE VAYA A GUARDAR UN JSON ESTANDAR --> que puedo abrir por ejemplo con firefox



#notamos que interpreta bien el numero de datos que tenemos

"""__Activity__: 
* Save to a file instead of `None` and open the file with some editor. 
"""

df.to_json('presidents.json',orient='records')

"""* Add a break-line at the end of the first dictionary and try to
load the resulting file with `pd.read_json`
"""

pd.read_json('presidents.json')

# %load presidents.json
[{"Name":"Donald Trump","Age":74},{"Name":"Barak Obama","Age":59}]

"""JSON allows for some flexibility in the break-lines structure:"""

hm='''
hola
mundo
'''

hm

[
    {"Name":
     "Donald Trump","Age":74},{"Name": #en cualquier parte
                               "Barak Obama","Age":59}

#Un comentario
]

pd.read_json('''
             [{"Name":"Donald Trump","Age":73},
              {"Name":"Barak Obama", "Age":58}]
            ''')        #importante las comillas dobles si lo quiero en formato de json

"""For large databases it is convinient just to accumulate dictionaries in a sequential form:"""

print(df.to_json(None,orient='records',lines=True))   #forzar json separados por rupturas de linea  ---> esto es recomendado solo cuando el json es demasiado grande

df=pd.read_json('''
             {"Name":"Donald Trump, Junior","Age":73}
             {"Name":"Barak Obama, Senior", "Age":58}
            ''',orient='records',lines=True)                   #se debe poner la misma opcion de lineas para que se lea correctamente

df

df["name"]=df['Name'].str.split(', ').str[0]               #el atributo str interpreta todo lo que hay dentro como una cadena de caracteres  -> a un string se le puede hacer un split

# --> el split cambia los espacios en blanco por elementos de una lista
#  en este caso separamos en lista los elementos que tales que entre ellos haya ', '

df

#un string es una lista de letras (tenerlo en cuenta)

df=pd.read_json('''
             {"Name":"Donald Trump Junior","Age":73}
             {"Name":"Barak Obama Senior", "Age":58}
            ''',orient='records',lines=True)

df

l=['A','B']

' '.join(l)            #usar el metodo join de la lista para juntar los elementos que haya en la lista. em ' ' ponemos con lo que la queremos seprar. En este caso la 
                       #estaríamos separando con un espacio

df['name']=df.Name.str.split().str[:-1].apply(lambda s: ' '.join(s))    #[:-1] toma los elementos hasta el penultimo
df

"""__Activity__: 
* Save to a file instead of `None`, with options: `orient='records',lines=True`, and open the file with some editor. 
"""

df.to_json('presidents.json',orient='records',lines=True)

cat presidents.json

"""* Add a similar dictionary in the next new line, and try to
load the resulting file with `pd.read_json` with options: `orient='records',lines=True`. 
   * WARNING: Use doble-quotes `"` to write the keys od the new
dictionary
"""

pd.read_json('presidents.json',orient='records',lines=True)

"""Any Python string need to be converted first to double-quotes before to be used as JSON string.

__Example__
"""

numbers={"even": [0,2,4,-6,8],   #  First  key-list
         "odd" : [1,3,-5,7,9] }  #  Second key-list

numbers

str(numbers)

"""This string can be writing in the `JSON` format by replacing the single quotes, ' , by  duoble quotes, ":"""

"hola mundo cruel".replace('cruel','radiante')

str(numbers).replace("'",'"')

"""and now can be used as an JSON input"""

df=pd.read_json(  str(numbers).replace("'",'"') )     #cambio las comillas simples a las doblea para recuperar el rormato de json correcto
df

"""__Activity__: Try to read the string as JSON without make the double-quote replacement

## Common operations upon `DataFrames`

See https://github.com/restrepo/PythonTipsAndTricks

* __To fill a specific cell__
"""

df.at[0,'Company']='Federación de Caferos'

df

"""## Filters (masking)

The main application of labeled data for data analysis is the possibility to make filers, or cuts, to obtain specific reduced datasets to further analysis
"""

import pandas as pd

numbers={"even": [0,2,4,-6,8],   #  First  key-list
         "odd" : [1,3,-5,7,9] }  #  Second key-list

df=pd.DataFrame(numbers)

df

"""A _mask_ is a list of `True/False` values"""

df.even.abs()>4   #en las columnas de pares puedo filtrar los elementos que requiero

df[df.even.abs()>4]    #poniendo las mascaras denttro del dataframe obtendo los datos filtrados

"""and → `&`"""

df[(df.even>0) & (df.odd<0)]          #si hay dos filtros de debe poner por lo menos la primera entre paréntesis

"""negation → `~`"""

df[~((df.even>0) & (df.odd<0)) ]          #si niego tengo el resto de filas

"""or → `|`"""

df[(df.even<0) | (df.odd<0)]          #pares negativos o impares negativos   es el O

"""## The `apply` method

The advantage of the spreadsheet paradigm is that the columns can be transformed with functions. All the typical functions avalaible for a spreadsheet are already implemented like the method `.abs()` used before, or the method: `.sum()`

EL APPLY SE USA CUANDO NO HAY FUNCIONES PREDEFINIDAS
"""

df.even.sum()

"""__Activity__: Explore the avalaible methods by using the completion system of the notebook after the last semicolon of `df.even.`"""

kk=df['even']

kk.

"""df['even'].ipynb_checkpoints/

### Column-level `apply`
We just select the column and apply the direct or implicit function:
* Pre-defined function
"""

df.even.apply(abs)

"""* Implicit function"""

df.even.apply(lambda n:isinstance(n,int))   #puedo definir la funcion implicitamente

df.even.apply(lambda n: n**2)

"""### Row-level apply
The foll row is passed as dictionary to the explicit or implicit function when `apply` is used for the full `DataFrame` and the option `axis=1` is used at the end
"""

df

df['even']+df['odd']**2            #funciona como hacer operaciones entre columnas

df.apply(lambda row: row['even']+row['odd']**2,axis='columns')   #row es el diccionario asociado a cada fila --> hago operaciones entre fila para crear una nueva columna

df.apply(lambda row: row.get('even')+row.get('odd')**2,axis='columns')

#get es una forma mas segura de recuperarun dato
# en caso de que no exista saldrá NONE en lugar de ERROR

"""## Chain tools for data analysis

There are several chain tools for data analyis like the
* Spreadsheet based one, like Excel 
* Relational databases with the use of more advanced SQL tabular data with some data base software like MySQL
* Non-relational databases (RAM) with Pandas, R,  Paw,... ( max ~ RAM/8) 
* Non-relational databases (Disk): Dask, ROOT, MongoDB,...

Here we illustrate an example of use fo a non-relational database with Pandas

## Relational databases
"""

import pandas as pd

personas=pd.read_csv('https://raw.githubusercontent.com/restrepo/ComputationalMethods/master/data/personas.csv')
#personas=pd.read_csv('../data/personas.csv')
personas

import pandas as pd
trabajos=pd.read_csv('https://raw.githubusercontent.com/restrepo/ComputationalMethods/master/data/trabajos.csv',
                     na_filter=False)
trabajos

#donde hay dos o mas trabajos, para no repetir elementos en la tabla, se crea una aparte

#esto es una base de datos relacional

"""![img](https://raw.githubusercontent.com/restrepo/ComputationalMethods/master/material/figures/relation.svg)

### Activity
Obtain the current work of Álavro Uribe Vélez
"""

trabajos

!pip install unidecode

import unidecode

unidecode.unidecode('Álvaro de Uribe').lower()

cc=personas[personas['Nombre'].str.lower().apply(
    unidecode.unidecode).str.contains('alvaro uribe velez')].iloc[0].get('id')           #se normaliza la cadena de caracteres unidecode para quitar acentos raros y se pone todo en minuscula


#contains encuentra una cadena de caracteres
# se recorreo nombre, se establece una mascara, luego, nos interesa obtener el identificador

trabajos[trabajos.get('id')==cc]['Cargo'].to_list()

"""## Non-relational databases

Listas de diccionarios anidados con una esquema de datos definido

![img](https://raw.githubusercontent.com/restrepo/ComputationalMethods/master/material/figures/personajes.svg)
"""

#cudrado --> lista
#elipse es un diccionario

personas['Fecha de Nacimiento']=pd.to_datetime( personas['Fecha de Nacimiento'] )   #convertimos la fecha de naciemiento a un formato apropiado de fecha

personas

"""Extract-Transform-Load: ETL"""

#ETL extraer, transformar y cargar, para convertir entre bases de datos relacionales o no

from dateutil.relativedelta import relativedelta

personas['Edad']=personas['Fecha de Nacimiento'].apply(lambda t: 
                        relativedelta( pd.to_datetime('now'), t).years )

trabajos[trabajos['id']==666].to_dict(orient='records')

personas

personas['id']

personas['Trabajos']=personas['id'].apply(lambda i:  trabajos[trabajos['id']==i
                                                             ][['Inicio','Fin','Cargo','Compañía']
                                                              ].to_dict(orient='records') )

personas             #esta ya es una base de datos no relacional

personajes=personas[['Nombre','Edad','Trabajos']]

personajes

personajes.to_dict(orient='records')

from IPython.display import JSON

JSON( personajes.to_dict(orient='records') )

"""### Actividad
Obtenga el último trabajo de Álvaro Uribe Vélez
"""

personajes[personajes['Nombre']=='Álvaro Uribe Vélez'
          ].get('Trabajos'
          ).apply(lambda l: [d.get('Cargo') for d in l if not d.get('Fin')]
          ).str[0].to_list()[0]

"""We have shown that the simple two dimensional spreadsheets where each cell values is a simple type like string, integer, or float, can be represented as a dictionary of lists values or a list of dictionary column-value assignment. 

We can go further and allow to store in the value itself a more general data structure, like nested lists and dictionaries. This allows advanced data-analysis when the `apply` methos is used to operate inside the nested lists or dictionaries.

See for example:

##  World wide web
There are really three kinds of web
* The normal web, 
* The deep web,
* _The machine web_. The web for machine readable responses. It is served in `JSON` or `XML`  formats, which preserve programming objects.

### Normal web
"""

pd.read_html('https://en.wikipedia.org/wiki/COVID-19_pandemic_by_country_and_territory')[0][1:]

"""Real world example: microsoft academics
![img](https://docs.microsoft.com/en-us/academic-services/graph/media/erd/entity-relationship-diagram.png)

### Machine web

For example, consider the following normal web page:

https://inspirehep.net/literature?q=doi:10.1103/PhysRevLett.122.132001

about a Scientific paper with people from the University of Antioquia. A _machine web_ version can be easily obtained in JSON just by attaching the extra parameter `&of=recjson`, and direcly loaded from Pandas, which works like a _browser for the third web_:
"""

import pandas as pd

df=pd.read_json('https://inspirehep.net/api/literature?q=doi:10.1103/PhysRevLett.122.132001')

df

""" We can use all the previous methods to extract the authors from `'Antioquia U.'`:
 
 Note: For a dictionary, `d` is safer to use `d.get('key')` instead of just `d['key']` to obtain some `key`, because not error is generated if the requested `key` does not exists at all 
"""

df[df['hits'].apply(lambda l: isinstance(l,list))]['hits' # extract cell with list
            ].apply(lambda l: [d.get('metadata') for d in l] # metadata of article
            ).str[0 #get the matched article dictionary
            ].str['authors' # get list of authors → l
            ].apply(lambda l: [ f'{d.get("first_name")} {d.get("last_name")}' for d in l  #author is a dictionary → d
                               #d.get('affiliations') is a list  of dictionaries → dd                               
                               if 'Antioquia U.' in [dd.get('value') for dd in d.get('affiliations')] 
                              ])

"""or"""

Authors=df[df['hits'].apply(lambda l: isinstance(l,list))]['hits' # extract cell with list
            ].apply(lambda articles: [article.get('metadata') for article in articles] # metadata of article
            ).str[0 #get the matched article dictionary
            ].str['authors' # get list of authors → l
            ]
Authors

names=Authors.apply(lambda authors: [ author.get('full_name') for author in authors  #author is a dictionary
                               #author.get('affiliations') is a list  of dictionaries → affiliation                              
                               if 'Antioquia U.' in [affiliation.get('value') for affiliation in author.get('affiliations')] 
                              ])
names[0]

"""We can see that the column `authors` is quite nested: Is a list of dictionaries with the full information for each one of the authors of the article.

__Activity__: Check that the lenght of the auhors list coincides with the `number_of_authors` 
<!-- df.authors.apply(len),df.number_of_authors.values -->
"""

len(names[0])

"""For further details see: https://github.com/restrepo/inspire/blob/master/gfif.ipynb

__Activity__: Repeat the same activity but using directly the JSON file, obtained with `requests`
"""

#See: https://github.com/inspirehep/rest-api-doc/issues/4#issuecomment-645218074
import requests                                                                                                                                                      
response = requests.get('https://inspirehep.net/api/doi/10.1103/PhysRevLett.122.132001')                                                                              
authors = response.json()['metadata']['authors']                                                                                                                     
names = [author.get('full_name')
              for author in authors 
               if any(aff.get('value') == 'Antioquia U.' for aff in author.get('affiliations'))]
names

#ahora, en lugar de mirar los de la universidad de antioquia vamos a mirar los integrantes de la universidad de los andes


#See: https://github.com/inspirehep/rest-api-doc/issues/4#issuecomment-645218074
import requests                                                                                                                                                      
response = requests.get('https://inspirehep.net/api/doi/10.1103/PhysRevLett.122.132001')                                                                              
authors = response.json()['metadata']['authors']                                                                                                                     
names = [author.get('full_name')
              for author in authors 
               if any(aff.get('value') == 'Andes U., Bogota' for aff in author.get('affiliations'))]
names

"""## Summary
[Pandas_Cheat_Sheet PDF](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)

##  ACTIVITIES
See:
* https://github.com/ajcr/100-pandas-puzzles
* https://github.com/guipsamora/pandas_exercises
* https://rramosp.github.io/ai4eng.v1/content/NOTES%2002.04%20-%20PANDAS.html

## Final remarks
With basic scripting and Pandas we already have a solid environment to analyse data. We introduce the other libraries motivated with the extending the capabilities of Pandas
"""

## Appendix

[Summary with ChatGPT](https://htmlpreview.github.io/?https://raw.githubusercontent.com/restrepo/ComputationalMethods/master/material/ChatGPT/Pandas.html)

"""<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=f91b818d-f536-4b8f-81de-61752e0979b7' target="_blank">
<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>
Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>
"""